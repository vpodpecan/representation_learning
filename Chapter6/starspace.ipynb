{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StarSpace\n",
    "\n",
    "StarSpace [[1]](#fn1) is an example of the entity embedding approach which uses a similarity function between entities to construct a prediction task for a neural network. It learns to represent objects of different types into a common vector space where they can be compared do each other. The problems that StarSpace can solve include learning word, sentence and document level embeddings, ranking, text classification, embedding graphs, image classification etc.\n",
    "\n",
    "This notebook requires a working SparSpace program which can be built on any modern Linux or Windows machine as described in the builind instructions in its [GitHub repository](https://github.com/facebookresearch/StarSpace). In addition, the following packages are required:\n",
    "\n",
    "- gensim==3.8.3\n",
    "- matplotlib==3.3.2\n",
    "- scikit-learn==0.23.2\n",
    "\n",
    "-----\n",
    "<span id=\"fn1\"> [1] Ledell Yu Wu, Adam Fisch, Sumit Chopra, Keith Adams, Antoine Bordes, and Jason Weston. Starspace: Embed all the things! In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, pages 5569–5577, 2018. </span>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow the official documentation of StarSpace and rewrite the text classification example. First of all, we need to compile the starspace binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'StarSpace'...\n",
      "remote: Enumerating objects: 5, done.\u001b[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 873 (delta 0), reused 0 (delta 0), pack-reused 868\u001b[K\n",
      "Receiving objects: 100% (873/873), 3.05 MiB | 654.00 KiB/s, done.\n",
      "Resolving deltas: 100% (567/567), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone git@github.com:facebookresearch/StarSpace.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -g -c src/utils/normalize.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/dict.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -g -c src/utils/args.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/proj.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/parser.cpp -o parser.o\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/data.cpp -o data.o\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/model.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/starspace.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/doc_parser.cpp -o doc_parser.o\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/doc_data.cpp -o doc_data.o\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/utils/utils.cpp -o utils.o\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops normalize.o dict.o args.o proj.o parser.o data.o model.o starspace.o doc_parser.o doc_data.o utils.o -I/usr/local/bin/boost_1_63_0/ -g src/main.cpp -o starspace\n"
     ]
    }
   ],
   "source": [
    "!cd StarSpace && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The executable is now available as `data/StarSpace/starspace`. The original bash script for the text classification example is available in the [Starspace GitHub repository](https://github.com/facebookresearch/Starspace/blob/master/examples/classification_ag_news.sh). We will reimplement it as a Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is based on [Antonio Gulli's corpus (AG)](http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html) which is a collection of more than 1 million news articles. Zhang et al. [[2]](#fn2) used it to construct a smaller corpus by choosing 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is thus 120,000 for training and 7,600 for testing. Let's download, unpack and inspect the corpus.\n",
    "\n",
    "----\n",
    "<span id=\"fn2\"> [2] Xiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-10 16:08:16--  https://dl.fbaipublicfiles.com/starspace/ag_news_csv.tar.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 2606:4700:10::6816:4b8e, 2606:4700:10::ac43:904, 2606:4700:10::6816:4a8e, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|2606:4700:10::6816:4b8e|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "ag_news_csv/\n",
      "ag_news_csv/train.csv\n",
      "ag_news_csv/test.csv\n",
      "ag_news_csv/classes.txt\n",
      "ag_news_csv/readme.txt\n",
      "ag_news_csv  ag_news_csv.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!wget -c https://dl.fbaipublicfiles.com/starspace/ag_news_csv.tar.gz -P data\n",
    "!cd data && tar -xzvf ag_news_csv.tar.gz\n",
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four classes and each news from the train and test set is classified using the line number of the actual class value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World\n",
      "Sports\n",
      "Business\n",
      "Sci/Tech\n",
      "\"3\",\"Wall St. Bears Claw Back Into the Black (Reuters)\",\"Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\"\n",
      "\"3\",\"Carlyle Looks Toward Commercial Aerospace (Reuters)\",\"Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\"\n",
      "\"3\",\"Oil and Economy Cloud Stocks' Outlook (Reuters)\",\"Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\"\n",
      "\"3\",\"Iraq Halts Oil Exports from Main Southern Pipeline (Reuters)\",\"Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.\"\n",
      "\"3\",\"Oil prices soar to all-time record, posing new menace to US economy (AFP)\",\"AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.\"\n"
     ]
    }
   ],
   "source": [
    "!cat data/ag_news_csv/classes.txt\n",
    "!head -n 5 data/ag_news_csv/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the data into a Pandas DataFrame object and perform text processing. The text will be converted to lowercase and a number of characters will be replaced. The category also needs to be prefixed with `__label__` as required for the FastText file format. The transformed data will be shuffled and written back into a FastText compatible text file. As shown below, both the train and test data are perfectly balanced on four categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File train.csv\n",
      "{'__label__business': 30000,\n",
      " '__label__scitech': 30000,\n",
      " '__label__sports': 30000,\n",
      " '__label__world': 30000}\n",
      "File test.csv\n",
      "{'__label__business': 1900,\n",
      " '__label__scitech': 1900,\n",
      " '__label__sports': 1900,\n",
      " '__label__world': 1900}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "idx2category = {1: '__label__world',2: '__label__sports', 3:'__label__business', 4:'__label__scitech'}\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.replace({'category': idx2category})\n",
    "    df['text'] = df['title'] + ' ' + df['body']\n",
    "    df = df.drop(labels=['title', 'body'], axis=1)\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    for s, rep in [(\"'\",\" ' \"),\n",
    "                   ('\"',''),\n",
    "                   ('.',' . '),\n",
    "                   ('<br />',' '),\n",
    "                   (',',' , '),\n",
    "                   ('(',' ( '),\n",
    "                   (')',' ) '),\n",
    "                   ('!',' ! '),\n",
    "                   ('?',' ? '),\n",
    "                   (';',' '),\n",
    "                   (':',' '),\n",
    "                   ('\\\\',''),\n",
    "                   ('  ',' ')\n",
    "                  ]:\n",
    "        df['text'] = df['text'].str.replace(s, rep)   \n",
    "    df = df.sample(frac=1)\n",
    "    return df\n",
    "\n",
    "for filename in ['data/ag_news_csv/train.csv','data/ag_news_csv/test.csv']:\n",
    "    df = pd.read_csv(filename, names=['category', 'title', 'body'])\n",
    "    df = preprocess(df)\n",
    "    print('File {}'.format(os.path.split(filename)[1]))\n",
    "    pprint(df['category'].value_counts().to_dict())\n",
    "    with open('{}.pp'.format(os.path.splitext(filename)[0]), 'w') as fp:\n",
    "        for row in df.itertuples():\n",
    "            fp.write('{} {}\\n'.format(row.category, row.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run StarSpace on the preprocessed files. The set of parameters will be the same as in the example from the StarSpace repository. The `trainMode=0` and `fileFormat='FastText'` combinations defines the mode where the labels are individual words, i.e., a classification task. We will use exactly the same settings as in the official example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: \n",
      "lr: 0.01\n",
      "dim: 10\n",
      "epoch: 5\n",
      "maxTrainTime: 8640000\n",
      "validationPatience: 10\n",
      "saveEveryEpoch: 0\n",
      "loss: hinge\n",
      "margin: 0.05\n",
      "similarity: dot\n",
      "maxNegSamples: 10\n",
      "negSearchLimit: 5\n",
      "batchSize: 5\n",
      "thread: 20\n",
      "minCount: 1\n",
      "minCountLabel: 1\n",
      "label: __label__\n",
      "label: __label__\n",
      "ngrams: 1\n",
      "bucket: 2000000\n",
      "adagrad: 0\n",
      "trainMode: 0\n",
      "fileFormat: fastText\n",
      "normalizeText: 0\n",
      "dropoutLHS: 0\n",
      "dropoutRHS: 0\n",
      "useWeight: 0\n",
      "weightSep: :\n",
      "Start to initialize starspace model.\n",
      "Build dict from input file : data/ag_news_csv/train.pp\n",
      "Read 5M words\n",
      "Number of words in dictionary:  94698\n",
      "Number of labels in dictionary: 4\n",
      "Loading data from file : data/ag_news_csv/train.pp\n",
      "Total number of examples loaded : 120000\n",
      "Training epoch 0: 0.01 0.002\n",
      "Epoch: 100.0%  lr: 0.008000  loss: 0.032078  eta: <1min   tot: 0h0m0s  (20.0%)%  lr: 0.009767  loss: 0.122484  eta: <1min   tot: 0h0m0s  (1.3%)69.7%  lr: 0.008383  loss: 0.035938  eta: <1min   tot: 0h0m0s  (13.9%)82.3%  lr: 0.008150  loss: 0.034168  eta: <1min   tot: 0h0m0s  (16.5%)\n",
      " ---+++                Epoch    0 Train error : 0.03181569 +++--- ☃\n",
      "Training epoch 1: 0.008 0.002\n",
      "Epoch: 100.0%  lr: 0.006250  loss: 0.017275  eta: <1min   tot: 0h0m0s  (40.0%).1%  lr: 0.007717  loss: 0.018359  eta: <1min   tot: 0h0m0s  (22.2%)25.3%  lr: 0.007500  loss: 0.019540  eta: <1min   tot: 0h0m0s  (25.1%)93.4%  lr: 0.006367  loss: 0.017560  eta: <1min   tot: 0h0m0s  (38.7%)\n",
      " ---+++                Epoch    1 Train error : 0.01784224 +++--- ☃\n",
      "Training epoch 2: 0.006 0.002\n",
      "Epoch: 100.0%  lr: 0.004000  loss: 0.014532  eta: <1min   tot: 0h0m1s  (60.0%)9.2%  lr: 0.004317  loss: 0.014935  eta: <1min   tot: 0h0m1s  (55.8%)\n",
      " ---+++                Epoch    2 Train error : 0.01494393 +++--- ☃\n",
      "Training epoch 3: 0.004 0.002\n",
      "Epoch: 100.0%  lr: 0.002000  loss: 0.013254  eta: <1min   tot: 0h0m1s  (80.0%) lr: 0.003783  loss: 0.017966  eta: <1min   tot: 0h0m1s  (60.9%)14.2%  lr: 0.003650  loss: 0.014057  eta: <1min   tot: 0h0m1s  (62.8%)23.7%  lr: 0.003483  loss: 0.012505  eta: <1min   tot: 0h0m1s  (64.7%)58.6%  lr: 0.002650  loss: 0.012937  eta: <1min   tot: 0h0m1s  (71.7%)85.5%  lr: 0.002133  loss: 0.013431  eta: <1min   tot: 0h0m1s  (77.1%)\n",
      " ---+++                Epoch    3 Train error : 0.01288906 +++--- ☃\n",
      "Training epoch 4: 0.002 0.002\n",
      "Epoch: 100.0%  lr: 0.000133  loss: 0.010625  eta: <1min   tot: 0h0m2s  (100.0%).5%  lr: 0.000800  loss: 0.011381  eta: <1min   tot: 0h0m1s  (93.3%)\n",
      " ---+++                Epoch    4 Train error : 0.01125932 +++--- ☃\n",
      "Saving model to file : data/ag_news_csv/model\n",
      "Saving model in tsv format : data/ag_news_csv/model.tsv\n"
     ]
    }
   ],
   "source": [
    "!./StarSpace/starspace train \\\n",
    "  -trainFile \"data/ag_news_csv/train.pp\" \\\n",
    "  -model \"data/ag_news_csv/model\" \\\n",
    "  -initRandSd 0.01 \\\n",
    "  -adagrad false \\\n",
    "  -ngrams 1 \\\n",
    "  -lr 0.01 \\\n",
    "  -epoch 5 \\\n",
    "  -thread 20 \\\n",
    "  -dim 10 \\\n",
    "  -negSearchLimit 5 \\\n",
    "  -trainMode 0 \\\n",
    "  -label \"__label__\" \\\n",
    "  -similarity \"dot\" \\\n",
    "  -verbose false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting starspace model is the embedding of the input into a common space which is 10-dimensional in our case (remember the `-dim 10` setting). It can be easily loaded into a dataframe and inspected. As shown in the table below, the model embedds everything into a common space: words that are present in documents but also the categories (the last four rows). This way, we are free to compare entities of different kinds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.012805</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>-0.014069</td>\n",
       "      <td>0.037838</td>\n",
       "      <td>-0.020683</td>\n",
       "      <td>-0.100598</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>-0.064737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>0.012291</td>\n",
       "      <td>-0.020647</td>\n",
       "      <td>-0.005732</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.007939</td>\n",
       "      <td>0.029393</td>\n",
       "      <td>-0.015839</td>\n",
       "      <td>-0.009221</td>\n",
       "      <td>-0.006826</td>\n",
       "      <td>0.030366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>0.014190</td>\n",
       "      <td>-0.031597</td>\n",
       "      <td>0.019656</td>\n",
       "      <td>0.018430</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>-0.013080</td>\n",
       "      <td>0.034038</td>\n",
       "      <td>0.033295</td>\n",
       "      <td>0.019923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>-0.018692</td>\n",
       "      <td>-0.010998</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>-0.088141</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>-0.001971</td>\n",
       "      <td>0.046167</td>\n",
       "      <td>-0.050714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>-0.004290</td>\n",
       "      <td>0.027648</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.017618</td>\n",
       "      <td>-0.025623</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.017099</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.011998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94697</th>\n",
       "      <td>hand-to-hand</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>-0.020686</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>-0.028212</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>-0.018049</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>-0.016406</td>\n",
       "      <td>0.000593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94698</th>\n",
       "      <td>__label__business</td>\n",
       "      <td>-0.096305</td>\n",
       "      <td>0.075784</td>\n",
       "      <td>-0.090052</td>\n",
       "      <td>-0.233349</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>-0.265917</td>\n",
       "      <td>0.222153</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.356689</td>\n",
       "      <td>0.134585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94699</th>\n",
       "      <td>__label__scitech</td>\n",
       "      <td>0.029514</td>\n",
       "      <td>-0.248513</td>\n",
       "      <td>0.031928</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>-0.443912</td>\n",
       "      <td>-0.124359</td>\n",
       "      <td>0.026620</td>\n",
       "      <td>0.110927</td>\n",
       "      <td>0.017640</td>\n",
       "      <td>-0.150377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94700</th>\n",
       "      <td>__label__world</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>0.127961</td>\n",
       "      <td>0.114498</td>\n",
       "      <td>0.191659</td>\n",
       "      <td>0.071189</td>\n",
       "      <td>0.209188</td>\n",
       "      <td>-0.016802</td>\n",
       "      <td>-0.242704</td>\n",
       "      <td>0.146559</td>\n",
       "      <td>-0.245721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94701</th>\n",
       "      <td>__label__sports</td>\n",
       "      <td>0.049872</td>\n",
       "      <td>0.061345</td>\n",
       "      <td>-0.046330</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>0.307533</td>\n",
       "      <td>0.165449</td>\n",
       "      <td>-0.237453</td>\n",
       "      <td>0.054204</td>\n",
       "      <td>-0.508677</td>\n",
       "      <td>0.282029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94702 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         1         2         3         4         5   \\\n",
       "0                      .  0.007482  0.003819  0.012805  0.023903 -0.014069   \n",
       "1                    the  0.012291 -0.020647 -0.005732  0.001266  0.007939   \n",
       "2                      ,  0.014190 -0.031597  0.019656  0.018430  0.028667   \n",
       "3                        -0.018692 -0.010998  0.024330  0.028363 -0.088141   \n",
       "4                     to -0.004290  0.027648  0.003929  0.017618 -0.025623   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "94697       hand-to-hand  0.010720 -0.020686 -0.004865  0.016998 -0.028212   \n",
       "94698  __label__business -0.096305  0.075784 -0.090052 -0.233349  0.024357   \n",
       "94699   __label__scitech  0.029514 -0.248513  0.031928  0.022888 -0.443912   \n",
       "94700     __label__world  0.031889  0.127961  0.114498  0.191659  0.071189   \n",
       "94701    __label__sports  0.049872  0.061345 -0.046330  0.029709  0.307533   \n",
       "\n",
       "             6         7         8         9         10  \n",
       "0      0.037838 -0.020683 -0.100598  0.019306 -0.064737  \n",
       "1      0.029393 -0.015839 -0.009221 -0.006826  0.030366  \n",
       "2     -0.000426 -0.013080  0.034038  0.033295  0.019923  \n",
       "3      0.007864  0.014710 -0.001971  0.046167 -0.050714  \n",
       "4      0.008797  0.000542  0.017099  0.002773  0.011998  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "94697  0.002781 -0.018049  0.001938 -0.016406  0.000593  \n",
       "94698 -0.265917  0.222153  0.049783  0.356689  0.134585  \n",
       "94699 -0.124359  0.026620  0.110927  0.017640 -0.150377  \n",
       "94700  0.209188 -0.016802 -0.242704  0.146559 -0.245721  \n",
       "94701  0.165449 -0.237453  0.054204 -0.508677  0.282029  \n",
       "\n",
       "[94702 rows x 11 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/ag_news_csv/model.tsv', sep='\\t', header=None, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute predictions and measure the peformance. In test mode, StarSpace reports the hit@k evaluation metric which tells us how many correct answers are among the top k predictions. In our case where we assign only one category the hit@1 metris is relevant (although in the general case assigning tags to texts is a multi-label classification problem). Starspace achieves the score $hit@1=0.46$ which means that in 46% of test cases the model's first prediction is the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: \n",
      "lr: 0.01\n",
      "dim: 10\n",
      "epoch: 5\n",
      "maxTrainTime: 8640000\n",
      "validationPatience: 10\n",
      "saveEveryEpoch: 0\n",
      "loss: hinge\n",
      "margin: 0.05\n",
      "similarity: dot\n",
      "maxNegSamples: 10\n",
      "negSearchLimit: 50\n",
      "batchSize: 5\n",
      "thread: 10\n",
      "minCount: 1\n",
      "minCountLabel: 1\n",
      "label: __label__\n",
      "label: __label__\n",
      "ngrams: 1\n",
      "bucket: 2000000\n",
      "adagrad: 1\n",
      "trainMode: 0\n",
      "fileFormat: fastText\n",
      "normalizeText: 0\n",
      "dropoutLHS: 0\n",
      "dropoutRHS: 0\n",
      "useWeight: 0\n",
      "weightSep: :\n",
      "Start to load a trained starspace model.\n",
      "STARSPACE-2018-2\n",
      "Model loaded.\n",
      "Loading data from file : data/ag_news_csv/test.pp\n",
      "Total number of examples loaded : 7600\n",
      "Predictions use 4 known labels.\n",
      "------Loaded model args:\n",
      "Arguments: \n",
      "lr: 0.01\n",
      "dim: 10\n",
      "epoch: 5\n",
      "maxTrainTime: 8640000\n",
      "validationPatience: 10\n",
      "saveEveryEpoch: 0\n",
      "loss: hinge\n",
      "margin: 0.05\n",
      "similarity: dot\n",
      "maxNegSamples: 10\n",
      "negSearchLimit: 5\n",
      "batchSize: 5\n",
      "thread: 10\n",
      "minCount: 1\n",
      "minCountLabel: 1\n",
      "label: __label__\n",
      "label: __label__\n",
      "ngrams: 1\n",
      "bucket: 2000000\n",
      "adagrad: 1\n",
      "trainMode: 0\n",
      "fileFormat: fastText\n",
      "normalizeText: 0\n",
      "dropoutLHS: 0\n",
      "dropoutRHS: 0\n",
      "useWeight: 0\n",
      "weightSep: :\n",
      "Predictions use 4 known labels.\n",
      "Evaluation Metrics : \n",
      "hit@1: 0.461447 hit@10: 1 hit@20: 1 hit@50: 1 mean ranks : 1.69763 Total examples : 7600\n"
     ]
    }
   ],
   "source": [
    "!./StarSpace/starspace test \\\n",
    "  -model \"data/ag_news_csv/model\" \\\n",
    "  -testFile \"data/ag_news_csv/test.pp\" \\\n",
    "  -ngrams 1 \\\n",
    "  -dim 10 \\\n",
    "  -label \"__label__\" \\\n",
    "  -thread 10 \\\n",
    "  -similarity \"dot\" \\\n",
    "  -trainMode 0 \\\n",
    "  -verbose false \\\n",
    "  -predictionFile \"data/ag_news_csv/test.y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of starspace in this particular example is not great. It differs significantly from the published results [[1]](#fn1) where on this task the authors report 91.6% accuracy on the test set. Is is unclear what is the reason for this discrepancy. On the other hand, the performance of a baseline classifier based on tf-idf + SVM can be easily demonstrated. Its performance is similar to the the performance of the BOW + multinomial logistic regression reported in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "def to_tfidf(documents, dic=None, tfidf_model=None):\n",
    "    documents = [gensim.parsing.preprocessing.preprocess_string(doc) for doc in documents]\n",
    "    if dic is None:\n",
    "        dic = gensim.corpora.Dictionary(documents)\n",
    "        dic.filter_extremes()\n",
    "    bows = [dic.doc2bow(doc) for doc in documents]\n",
    "    if tfidf_model is None:\n",
    "        tfidf_model = gensim.models.tfidfmodel.TfidfModel(dictionary=dic)\n",
    "    tfidf_vectors = tfidf_model[bows]\n",
    "    return tfidf_vectors, dic, tfidf_model\n",
    "\n",
    "\n",
    "train = pd.read_csv('data/ag_news_csv/train.csv', names=['category', 'title', 'body'])\n",
    "X_train = [x.title + ' ' + x.body for x in train.itertuples()]\n",
    "y_train = [x.category for x in train.itertuples()]\n",
    "\n",
    "test = pd.read_csv('data/ag_news_csv/test.csv', names=['category', 'title', 'body'])\n",
    "X_test = [x.title + ' ' + x.body for x in test.itertuples()]\n",
    "y_test = [x.category for x in test.itertuples()]\n",
    "\n",
    "X_train_tfidf, dic, tfidf_model = to_tfidf(X_train)\n",
    "X_test_tfidf, _, __ = to_tfidf(X_test, dic, tfidf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf-idf model with combination with linear SVM achieves the accuracy of 91%. Because this is an ordinary multiclass classification problem, this metric is the same as hit@1 as reported by starspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.910\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(gensim.matutils.corpus2csc(X_train_tfidf, num_terms=len(dic)).T, le.transform(y_train))\n",
    "y_predicted = svc.predict(gensim.matutils.corpus2csc(X_test_tfidf, num_terms=len(dic)).T)\n",
    "print('Accuracy: {:.3f}'.format(metrics.accuracy_score(le.transform(y_test), y_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have embeddings for a large number of words, let's try to run clustering to see if the embeddings vectors can be used to partition words four categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = pd.read_csv('data/ag_news_csv/model.tsv', sep='\\t', header=None, keep_default_na=False)\n",
    "embeddings = model[model.columns[1:]]\n",
    "kmeans = KMeans(n_clusters=4, random_state=42).fit(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting clusters are quite interesting. The first three match very closely to topics World, Sci/Tech, and Business while the last and by far the largest is less specific and contains words from all topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 (1584 instances)\n",
      "['.' '-' \"'\" 'ap' 'iraq' 'york' 'president' 'says' 'sunday' 'would'\n",
      " 'security' 'government' 'people' 'afp' 'night' 'china' 'minister' 'bush'\n",
      " 'killed' 'stocks' 'european' 'talks' 'league' 'country' 'reported'\n",
      " 'british' 'japan' 'india' 'police' 'prime' 'iraqi' 'leader' 'say'\n",
      " 'baghdad' 'expected' 'election' 'her' 'north' 'under' 'war' 'australia'\n",
      " 'military' 'cut' 'nuclear' 'higher' 'un' 'official' 'palestinian' 'sox'\n",
      " 'attack' 'troops' 'russia' 'israeli' 'gaza' 'press' 'west' 'even'\n",
      " 'including' 'general' 'man' 'iran' 'football' 'released' 'forces'\n",
      " 'athens' 'past' 'europe' 'investors' 'peace' 'release' 'canadian'\n",
      " 'russian' 'beat' 'pakistan' 'public' 'eu' 'where' 'foreign'\n",
      " 'presidential' 'bomb' 'attacks' 'israel' 'nations' 'championship' 'korea'\n",
      " 'australian' 'kerry' 'leaders' 'french' 'men' 'face' 'death' 'killing'\n",
      " 'darfur' 'leading' 'arafat' '#36' 'seven' 'army' 'capital']\n",
      "\n",
      "Cluster 1 (1735 instances)\n",
      "['' '(' 'by' 'reuters' '&lt' 'first' 'u' 'company' 'microsoft' 't' 'game'\n",
      " 'software' 'internet' 'market' 'announced' 'news' '2004' 'service'\n",
      " 'technology' 'com' 'search' 'computer' 'space' 'online' 'what' 'network'\n",
      " 'google' 'ibm' 'research' 'music' 'help' 'games' 'web' 'san' 'industry'\n",
      " 'mobile' 'services' '4' 'quarter' 'wireless' 'system' 'data' 'i' 'phone'\n",
      " 'apple' 'oracle' 'windows' 'global' 'intel' 'found' 'users' 'reports'\n",
      " 'price' 'peoplesoft' 'case' 'use' 'uk' 'video' 'pc' 'systems' 'support'\n",
      " 'nasa' 'sun' 'contract' 'launch' 'linux' 'called' 'digital' 'scientists'\n",
      " 'net' 'used' 'program' 'version' 'future' 'center' 'site' 'products'\n",
      " 'customers' 'study' 'chip' 'sony' 'management' 'california' 'such'\n",
      " 'making' 'department' 'using' 'grand' 'ceo' 'university' 'tv' 'launched'\n",
      " 'times' 'source' 'server' 'too' 'better' 'phones' 'desktop' 'information']\n",
      "\n",
      "Cluster 2 (1803 instances)\n",
      "['us' 'oil' 'inc' 'yesterday' '?' 'corp' 'prices' 'years' 'group' 'time'\n",
      " 'season' 'deal' 'sales' 'business' 'billion' 'former' 'washington'\n",
      " 'profit' 'states' '/b&gt' 'b&gt' 'chief' 'american' 'shares' 'take'\n",
      " 'bank' 'third' 'federal' 'companies' 'co' 'maker' 'month' 'bid' 'hit'\n",
      " 'largest' 'big' 'giant' '5' 'growth' 'investor' '//www' 'href=http'\n",
      " '/a&gt' 'trade' 'earnings' 'dollar' 'buy' 'gold' 'union' 'john' 'amp'\n",
      " 'stock' 'loss' 'agreed' 'months' 'target=/stocks/quickinfo/fullquote&gt'\n",
      " 'com/fullquote' 'aspx' 'like' 'firm' 'air' 'rose' 'executive' 'jobs'\n",
      " 'update' 'boston' 'economy' 'drug' 'ahead' 'pay' 'near' 'biggest'\n",
      " 'economic' 'car' 'o' 'offer' 'street' 'work' 'your' 'free' '2005' 'much'\n",
      " '6' 'workers' 'wins' 'america' 'nation' 'share' 'financial' 'fall' 'wall'\n",
      " 'house' 'fell' 'lower' 'september' 'crude' 'october' 'following'\n",
      " 'chicago' 'job']\n",
      "\n",
      "Cluster 3 (89580 instances)\n",
      "['the' ',' 'to' 'a' 'of' 'in' 'and' 's' 'on' 'for' '#39' ')' 'that' 'with'\n",
      " 'as' 'at' 'is' 'its' 'new' 'it' 'said' 'has' 'from' 'an' 'his' 'will'\n",
      " 'after' 'was' 'be' 'over' 'have' 'their' 'are' 'up' 'quot' 'but' 'more'\n",
      " 'two' 'he' 'world' 'this' '--' 'monday' 'wednesday' 'tuesday' 'out'\n",
      " 'thursday' 'one' 'not' 'against' 'friday' 'into' 'they' 'about' 'last'\n",
      " 'year' 'than' 'who' 'no' 'were' 'been' 'million' 'week' 'had' 'united'\n",
      " 'when' 'could' 'three' 'today' 'which' 'may' 'percent' '1' 'win' 'off'\n",
      " 'team' 'next' 'back' 'saturday' 'or' '2' 'can' 'some' 'second' 'state'\n",
      " 'all' 'top' 'day' 'down' 'n' 'international' 'most' 'record' 'victory'\n",
      " 'officials' 'report' 'open' 'city' 'end' 'plans']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_array = model[0].to_numpy()\n",
    "for ci in range(kmeans.n_clusters):\n",
    "    cluster_words = np.compress(kmeans.labels_==ci, words_array)\n",
    "    print('Cluster {} ({} instances)'.format(ci, len(cluster_words)))\n",
    "    print(cluster_words[:100])\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
